---
title: "nbbp"
output:
  rmarkdown::html_vignette:
    fig_width: 7
    fig_height: 5
vignette: >
  %\VignetteIndexEntry{nbbp}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = F}
library(knitr)
knitr::opts_chunk$set(
  out.extra = 'style="display:block; margin:auto;"'
)
```

Welcome to `nbbp`, an R package for inference of parameters of negative binomial branching process models from final outbreak size data.
This vignette covers the basics of inferring parameters from simple data, where every possible chain size is observable and every observed chain size is known exactly.
More advanced forms of data are covered in the "Advanced data" vignette.
Note that a "chain" is not necessarily a linear structure and includes transmission trees.
That is, it consists of the first infected individual, any and all individuals infected by the first, any and all individuals infected by the second generation, and so forth.
But as we are working with the final size of a chain, each observation is simply an integer: the total number of infections, including the first.

As our example, we will analyze Borealpox.
Currently, there are seven singleton cases which have been observed, each corresponding to a final chain size of 1.
The data is included in the package, though we could have simply made it ourselves (e.g. `rep(1, 7)`).
```{r bpox data}
library(nbbp)
library(ggplot2)
data(borealpox)

borealpox
```

# Simple Bayesian inference

Fitting the model is accomplished by passing the data and the model object to `fit_nbbp_homogenous_bayes()`, which internally uses `rstan` for inference.
This function allows significant control over `rstan` settings, as well as adjustments to the default priors (for more on those, see the vignette "Default priors").
Here, for reproducibility, we will set the random seed, so that any time we run this code (with the same version of `rstan`) we will get the same answer.
```{r, results=FALSE}
fit <- fit_nbbp_homogenous_bayes(
  all_outbreaks = borealpox,
  seed = 42
)
```

The output is a regular `rstan::stanfit` object, and can be summarized in the usual ways.
As we are performing Bayesian inference, we should always check convergence diagnostics.
(For more on so doing, see the [stan manual](https://mc-stan.org/docs/reference-manual/analysis.html#convergence), the [rstan reference](https://cran.r-project.org/web/packages/rstan/rstan.pdf), or [Chapter 11.4 in Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/).)
```{r}
rstan::check_hmc_diagnostics(fit)

rstan::summary(fit)$summary[, c("n_eff", "Rhat")]
```

Now that we can see our MCMC is trustworthy, we can look at what our results are.
There are 5 variables tracked in the object.
Primarily, we have $R$ (`r_eff`) and $k$ (`dispersion`).
Additionally, we track two values which are functions of $R$ and $k$ but can be useful in their own right.
These are the probability that a chain goes extinct (`exn_prob`) and the probability that any one infection produces no additional infections (`p_0`).
As it is the native parameter of the model, we also have $1 / \sqrt{k}$ (`inv_sqrt_dispersion`)

Let us see what we have estimated.

```{r}
fit
```

We can see that the model is relatively confident $R < 1$, but there is still considerable uncertainty about its value.
We can see even greater uncertainty about $k$, which is typical in practice without a relatively large number of chains observed.

While `rstan` provides some basic plotting capabilities, this is not the only way to do so.
Here we extract and plot things ourselves directly with ggplot, though we could also use the `bayesplot` package which has many nice visualizations.
Plots show us
```{r}
par_df <- rstan::extract(fit, pars = c("r_eff", "dispersion", "p_0", "exn_prob")) |>
  as.data.frame()

par_df |>
  ggplot(aes(x = r_eff, y = after_stat(density))) +
  geom_histogram() +
  theme_minimal() +
  xlab("R")
```
Here we can see that the posterior density is greatest for small values of $R$, as well as the long tails with larger values.

The uncertainty about the dispersion parameter often makes it more usefully considered on the log-scale.
```{r}
par_df |>
  ggplot(aes(x = log(dispersion), y = after_stat(density))) +
  geom_histogram() +
  theme_minimal() +
  xlab("log(k)")
```
This shows us that, while there is considerable uncertainty, the model favors relatively strong overdispersion.

The probability that a chain goes extinct (`exn_prob`) is a function of $R$ and $k$.
```{r}
par_df |>
  ggplot(aes(x = exn_prob, y = after_stat(density))) +
  geom_histogram() +
  theme_minimal() +
  xlab("extinction probability")
```
It is always 1 when $R < 1$, so since there is a `r {round(mean(unlist(rstan::extract(fit, "r_eff")) < 1), 2) * 100}`% probability that $R < 1$, most of the prior mass is on 1 exactly.
Most of the rest of the mass is on values near 1, but we can see the considerably uncertainty about $R$ and $k$ manifest in the long left tail.
While it isn't probable that 7 chains went extinct if the extinction probability is only, say, 0.8, it is not impossible ($0.8^7 \approx 0.21$).


The probability of 0 offspring (`p_0`) is also a function of $R$ and $k$, and measures the probability that any particular infection produces no more infections.
```{r}
par_df |>
  ggplot(aes(x = p_0, y = after_stat(density))) +
  geom_histogram() +
  theme_minimal() +
  xlab("probability of 0 offspring")
```
Since we have not seen any chains produce offspring, we should not be surprised to see that this probability is near 1.
(When there is strong overdispersion (small $k$), this can be near 1 even when $R$ is above 1.)
We might expect, since none of these cases have produced any offspring, that the posterior would have a mode at 1.
However, the default priors pull towards regimes where this probability is smaller (larger $R$ and $k$ both make it more likely that an infection has offspring), as can be seen in the plot in the "Default priors" vignette.


# Simple maximum likelihood inference

The package also supports maximum likelihood inference.
We do not suggest using maximum likelihood as the primary form of inference, but sometimes one may wish to see the results.
This can be accomplished with `fit_nbbp_homogenous_ml()` which has much the same interface as `fit_nbbp_homogenous_bayes()`.
By default, this attempts to obtain 10 converged search replicates from random starting locations, and will adaptively determine an appropriate method for producing confidence intervals.
```{r, results=FALSE}
fit_ml <- fit_nbbp_homogenous_ml(
  all_outbreaks = borealpox,
  seed = 42,
  ci_width = 0.95
)
```

The object returned here is a slightly enriched version of what is returned by `rstan::optimizing` for the replicate search which produced the maximum maximized likelihood.

```{r bpox ml results}
fit_ml
```

Here, `$par` tells us our maximum likelihood estimates of the parameters (and the additionally-tracked variables), and `$ci` the confidence intervals (for only $R$ and $k$).
Additionally, `$convergence` returns the range of values of $R$, $k$, and the maximized likelihood across all search replicates.
When there are wide (relative to the value) ranges observed, this signals trouble.

Sometimes, we can understand the nature of issues with maximum likelihood inference by examining the likelihood surface.
The function `compute_likelihood_surface()` computes this at a grid and enables visualization.
```{r}
r_vec <- exp(seq(log(1e-4), log(2), length.out = 100))
k_vec <- exp(seq(log(0.01), log(9999), length.out = 100))

lnl_surface <- compute_likelihood_surface(
  borealpox,
  r_grid = r_vec,
  k_grid = k_vec
)

lnl_surface |>
  ggplot(aes(x = r, y = k, fill = log_dens)) +
  theme_minimal() +
  geom_tile() +
  scale_x_continuous(trans = "log") +
  scale_y_continuous(trans = "log") +
  xlab("R") +
  scale_fill_viridis_c(option = "magma")
```

Roughly speaking, the region where the log-likelihood is within 12 units of the maximum value is within a bivariate confidence region.
We can see there is extensive uncertainty here, as most of this plot is within a 12 log-likelihood unit range of the maximum.

We also see that the the log-likelihood surface does not appear to have a single mode.
It is easier to see what is going on if we focus in on where the likelihood is highest.

```{r}
r_vec <- exp(seq(log(1e-4), log(0.02), length.out = 100))

lnl_surface <- compute_likelihood_surface(
  borealpox,
  r_grid = r_vec,
  k_grid = k_vec
)

lnl_surface |>
  ggplot(aes(x = r, y = k, fill = log_dens)) +
  theme_minimal() +
  geom_tile() +
  scale_x_continuous(trans = "log") +
  scale_y_continuous(trans = "log") +
  xlab("R") +
  scale_fill_viridis_c(option = "magma")
```

The likelihood increases as $R$ decreases, but once $R$ gets small, for a fixed $R$ the likelihood appears to be constant in $k$.
The presence of this ridge shape, rather than a single mode, likely explains the convergence difficulties we saw with maximum likelihood estimation.
For sufficiently small $R$, we can pick any $k$ and not change the likelihood, so the value of $k$ the optimizer ends up giving us is going to depend a lot on where it started.

# "Is $R$ different?"

While inference in this package is focused on cases where $R$ is homogenous, we can still try to make comparisons about $R$ between scenarios.

## Measles
For example, we might ask if $R$ is different in the two measles datasets included in the package.
These correspond to cases in the United States from 1997-1999 and Canada from 1998-2001.
To investigate this, we can simply fit the model, separately, to both datasets and examine the posteriors.

```{r, results=FALSE, warning=FALSE}
data(measles_us_97)
data(measles_canada_98)

us <- fit_nbbp_homogenous_bayes(measles_us_97, iter = 5000, seed = 42)
canada <- fit_nbbp_homogenous_bayes(measles_canada_98, iter = 5000, seed = 42)
```

We have two sets of MCMC convergence diagnostics to check now.
```{r}
rstan::check_hmc_diagnostics(us)

rstan::summary(us)$summary[, c("n_eff", "Rhat")]
```
We would normally be troubled by a `NaN`.
However, when the posterior probability that $R < 1$ is 1, the extinction probability is always 1.
Convergence diagnostics make use of the variance of a quantity in the posterior, and therefore produce `NaN`s here.

```{r}
rstan::check_hmc_diagnostics(canada)

rstan::summary(canada)$summary[, c("n_eff", "Rhat")]
```


```{r}
r_df <- data.frame(
  r = c(
    unlist(rstan::extract(us, "r_eff")),
    unlist(rstan::extract(canada, "r_eff"))
  ),
  location = c(
    rep("US", 10000),
    rep("Canada", 10000)
  )
)

r_df |>
  ggplot(aes(x = r, fill = location, y = after_stat(density))) +
  geom_histogram(position = "identity", alpha = 0.7) +
  theme_minimal() +
  xlab("R")
```
The posterior distributions on $R$ exhibit rather low overlap, suggesting that $R$ is in fact different.

We can quantify this, if we like, by some measure of overlap of the posteriors.
We might, for example, contemplate what percent  of the posterior on $R_{\text{US}}$ is above the 2.5th percentile of the posterior on $R_{\text{Canada}}$.
We would then compute the 2.5th percentile of $R_{\text{Canada}}$, find that it is `r {unname(round(r_df |> dplyr::filter(location == "Canada") |> dplyr::pull(r) |> quantile(probs = 0.025), 2))}`, and count the percent of samples of $R_{\text{US}}$ which are larger than this and find that it is `r {round(mean(r_df |> dplyr::filter(location == "US") |> dplyr::pull(r) >= r_df |> dplyr::filter(location == "Canada") |> dplyr::pull(r) |> quantile(probs = 0.025)), 2) * 100}`%.
Or we could do this the other way around, and ask what percent  of the posterior on $R_{\text{Canada}}$ is below the which is below the 97.5th percentile of the posterior on $R_{\text{US}}$.
This is `r {round(mean(r_df |> dplyr::filter(location == "Canada") |> dplyr::pull(r) <= r_df |> dplyr::filter(location == "US") |> dplyr::pull(r) |> quantile(probs = 0.975)), 2) * 100}`%.

These summaries are not entirely satisfying, as we have both an arbitrary reference quantile and an asymmetric measure.
We could instead try to define, jointly, a single probability $\alpha$ and corresponding quantile $q$ such that $\text{Pr}(R_{\text{US}} > q \mid \text{data}) = \text{Pr}(R_{\text{Canada}} \leq q \mid \text{data}) = \alpha$.
That is, find the value of $R$ for which the posterior probability that $R_{\text{US}}$ is larger is equal to the posterior probability that $R_{\text{Canada}}$ is smaller.
Since $\text{Pr}(R_{\text{US}} \leq q \mid \text{data}) = 1 - \text{Pr}(R_{\text{US}} > q \mid \text{data})$, we can rearrange this equation and remove $\alpha$, simply writing $\text{Pr}(R_{\text{US}} \leq q \mid \text{data}) + \text{Pr}(R_{\text{Canada}} \leq q \mid \text{data}) = 1$.
Once we solve for $q$, we get our overlap percent ($\alpha \times 100$%) for free and can estimate it from our samples of either the posterior on $R_{\text{US}}$ or on $R_{\text{Canada}}$.
This can't simply be done in one chain of `dplyr` calls, so we will need to write some code.

```{r}
find_overlap <- function(r_small, r_large) {
  # As pointed out, ECDFs are more efficient
  # https://stats.stackexchange.com/questions/122857/how-to-determine-overlap-of-two-empirical-distribution-based-on-quantiles #nolint
  p_r_small <- stats::ecdf(r_small)
  p_r_large <- stats::ecdf(r_large)
  loss_fn <- function(q) {
    ((p_r_small(q) + p_r_large(q)) - 1)^2
  }
  optimize(loss_fn, range(c(r_small, r_large)))$minimum
}

q <- find_overlap(
  r_df |> dplyr::filter(location == "US") |> dplyr::pull(r),
  r_df |> dplyr::filter(location == "Canada") |> dplyr::pull(r)
)

overlap <- 1.0 - mean(
  r_df |>
    dplyr::filter(location == "US") |>
    dplyr::pull(r)
  <= q
)
```
This gives us an overlap of `r {round(overlap, 2) * 100}`%.

## MERS-CoV
As another example, we might ask if $R$ is different for MERS-CoV  in the Arabian Peninsula after June 1, 2013 (compared to before).
Again, we fit both datasets separately and compare.
```{r, results=FALSE, warning=FALSE}
data(mers_pre_june)
data(mers_post_june)

before <- fit_nbbp_homogenous_bayes(mers_pre_june, iter = 5000, seed = 42)
after <- fit_nbbp_homogenous_bayes(mers_post_june, iter = 5000, seed = 42)
```

Again we have two sets of MCMC convergence diagnostics to check.
```{r}
rstan::check_hmc_diagnostics(before)

rstan::summary(before)$summary[, c("n_eff", "Rhat")]
```

```{r}
rstan::check_hmc_diagnostics(after)

rstan::summary(after)$summary[, c("n_eff", "Rhat")]
```

```{r}
r_df <- data.frame(
  r = c(
    unlist(rstan::extract(before, "r_eff")),
    unlist(rstan::extract(after, "r_eff"))
  ),
  time = c(
    rep("before", 10000),
    rep("after", 10000)
  )
)

r_df |>
  ggplot(aes(x = r, fill = time, y = after_stat(density))) +
  geom_histogram(position = "identity", alpha = 0.7) +
  theme_minimal() +
  xlab("R")
```
The posterior for the later cases completely covers the posterior for the earlier ones.
Clearly, there is no evidence for a difference in $R$.
